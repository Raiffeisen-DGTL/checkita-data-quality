# Проверка Качества Потоковых Источников Данных

> **ВАЖНО** Функционал связанный с проверкой качества потоковых источников данных на данный момент находится в
> экспериментальной стадии, поэтому в нем возможны изменения.

Как уже было сказано, фреймворк Checkita способен рассчитывать метрики и выполнять проверки качества над потоковыми 
источниками данных. Так как Spark используется в качестве вычислительно ядра, то
[Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
API используется для вычисления метрик над потоковыми источниками данных.

Основная идея при запуске data quality пайплайна в потоковом режиме, это сохранить возможность обрабатывать 
несколько потоковых источников данных одновременно. Так как расчет метрик над источниками представляет собой операцию
с сохранением состояния, то все потоковые источники обрабатываются в "оконном" режиме: формируются временные окна,
отслеживающие состояние за данный промежуток времени. Для того чтобы одновременно обрабатывать несколько потоковых
источников, их окна должны быть синхронизированы: (1) они должны быть одного размера и (2) должны начинаться в 
одно и то же время. Чтобы это обеспечить, размер окон устанавливается на уровне приложение и является единым для 
всех обрабатываемых источников данных.

Поскольку потоковые источники обрабатываются по каждому окну, ключевым моментом является наличие временной метки для 
каждой записи, которая будет использована, чтобы поместить эту запись в то или иное окно. Поддерживается несколько 
опций, чтобы предоставить временную метку:

* `Processing time` - Spark формирует временную метку автоматически для каждой записи, когда она поступает в обработку.
  Для этого используется функция `current_timestamp`.
* `Event time` - В большей степени применимо к топикам Kafka: временная метка считывается из колонки `timestamp`, 
  в которой хранится время создания записи (event time).
* `Custom time` - Определяемая пользователем колонка типа *timestamp*, из которой будет считана временная метка.

Также необходимо выяснить то, когда можно считать какое-либо окно полностью сформированным. Другими словами, надо
установить правила, согласно которым можно будет считать состояние окна окончательными и предполагать, что никакие
другие записи больше не попадут в это окно. Распространенным подходом для решения этой проблемы при потоковой обработке
данных является использование так называемых "водяных знаков" (watermarks). Водяной знак содержит в себе временную
метку которая устанавливает уровень для принятия новых записей в обработку. Если временная метка записи "ниже" уровня
"водяного знака", то данная запись считается "опоздавшей" и не принимается в обработку. "Водяной знак" определяется как
максимальное значение временной метки у уже обработанных записей за вычетом заранее определенного смещения. Более
подробная информация об использовании подхода "водяных знаков" представлена в документации Spark:
[Handling Late Data and Watermarking](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#handling-late-data-and-watermarking).
Так, для цели синхронизированной обработки нескольких потоковых источников, уровень смещения для водяного знака 
устанавливается на уровне приложения и одинаков для всех источников.

Наконец, необходимо отметить, что движок Spark Structure Streaming обрабатывается потоковые источники в режиме 
микро-пакетов (micro-batches). Так, записи собираются за определенный (как правило, очень короткий) интервал времени
и далее обрабатываются как статичный датафрейм. Spark позволяет настраивать временной интервал за который будут
собираться записи в микро-пакет. Для этого задается `trigger` интервал. Данных интервал также должен быть единым для
всех обрабатываемых источников данных и устанавливается на уровне приложения. Настройка этого интервала позволяет
контролировать размер микро-пакетов данных и, как следствие, нагрузку на экзекьюторы.

Для более подробной информации о настройках для запуска data quality пайплайнов в потоковом режиме, см. главу
[Настройки потоковой обработки](../01-application-setup/01-ApplicationSettings.md#_3) chapter.
Подытожив, работа data quality пайплайна в потоковом режиме состоит из следующих этапов:

* Запуск spark streaming queries для каждого источника с записью в `forEachBatch sink`.
* Запуск процессора окон в отдельном потоке.
* Обработка данных каждого микро-пакета (формируется раз за `trigger` интервал):

    * регистрируется аккумулятор для сбора ошибок при вычислении метрик.
    * Для каждой записи вычисляется обновленное состояние калькуляторов метрик, которые соответствуют тому окну, 
      которому принадлежит данная запись.
    * собираются ошибки вычисления метрик (если таковые были).
    * Если временная метка записи ниже уровня текущего "водяного знака", то данная запись не принимается в обработку:
      состояние калькуляторов метрик и аккумулятора с ошибками остаются неизменными.
    * вычисляется новое значение водяного знака на основе значений временных меток из записей обработанных в текущем
      микро-пакете.
    * Обновляется состояние буфера процессора окон. Буфер содержит состояния калькуляторов метрик для каждого всех
      окон (начавших формироваться на текущий момент) также как и состояние аккумуляторов с ошибками вычисления метрик
      (также для всех окон). Помимо этого, буфер хранит текущие значения "водяных знаков" для всех обрабатываемых
      источников.

* Процессор окон проверяет буфер (также один раз за `trigger` интервал) на наличие окон, которые полностью 
  сформированы, т.е. находятся целиком ниже уровня "водяного знака". **ВАЖНО** Для того, чтобы иметь возможность
  обрабатывать потоковые источники синхронно, используется минимальное значение "водяного знака" (вычисляется на
  основе текущих значений "водяных знаков" всех обрабатываемых источников). Такой подход гарантирует, что окно будет
  полностью сформированным для всех обрабатываемых источников.
* Как только получено полностью сформированное окно, то для него выполняются все необходимые процедуры:

    * результаты расчета метрик извлекаются из финального состояния калькуляторов;
    * вычисляются композиционные метрики;
    * выполняются проверки качества;
    * результаты сохраняются в выделенное хранилище;
    * обрабатываются все "таргеты" и результаты (или уведомления) отправляются по указанным каналам.
    * очищается буфер процессора окон: состояние обработанного окна удаляется из буфера.

* Streaming queries и процессор окон выполняются до тех пор, пока приложение не будет остановлено
  (получен сигнал `sigterm`) или же пока не случится какая-либо ошибка.

**Важно замечание о сохранении результатов в хранилище**: поскольку набор результатов формируется для каждого окна,
то `referenceDate` и `executionDate` устанавливаются равными дате и времени старта данного окна. Для более подробной
информации по работе с датами во фреймворке, см. главу [Работа с Датами](01-WorkingWithDateTime.md).

> **СОВЕТ** Поскольку проверки качества данных выполняются для каждого окна, то размер этого окна скорее должен быть
> достаточно большим, чтобы предоставлять результаты с тем интервалом времени, который позволит за этим результатами
> следить и реагировать на какие-либо проблемы с качеством данных. Так, если "время реакции" вашей инженерной команды
> примерно 1 час, то и окно должно быть примерно с таким же интервалом. Нет особого смысла выполнять проверки на 
> потоковым источником каждые 10 минут, если у вас нет ресурсов на них реагировать.