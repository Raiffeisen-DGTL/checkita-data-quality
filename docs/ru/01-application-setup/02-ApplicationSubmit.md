# Запуск Приложений Data Quality

Поскольку Checkita фреймворк построен на основе Spark, то он запускается как обычное Spark-приложение используя
команду `spark-submit`. Как и любое другое Spark-приложение, приложение Checkita может быть запущено как локально,
так и в кластере (в режиме `client` или `cluster`).

Однако, приложения Checkita требуют передачи определенный аргументов при старте, а именно:

* `-a` - *Обязательно*. Путь до HOCON файла с настройками приложения: `applicaiton.conf`. Стоит отметить, что имя файла
  может быть другим, однако обычно используется файл с таким именем.
* `-j` - *Обязательно*. Список путей до файлов с конфигурациями Data Quality пайплайна. Пути должны быть разделены 
  запятыми. HOCON формат поддерживает слияние конфигурация, поэтому можно описывать различные части конфигурации
  пайплайна в отдельных файлах и переиспользовать их.
* `-d` - *Опционально*. Дата за которую запускается Data Quality пайплайн. Формат, в котором указана дата, должен 
  соответствовать тому, который указан в поле `referenceDateFormat` в настройках приложения. Если дата не указана,
  то ей будет присвоено значение фактической даты старта пайплайна.
* `-l` - *Опционально*. Аргумент, который указывает на то, что приложение должно быть запущено в локальном режиме.
* `-s` - *Опционально*. Аргумент, который указывает на то, что приложение будет запущено с использованием Shared
  Spark Context. В этом случае приложение будет получать существующий Spark Context, вместо того, чтобы создавать новый.
  Также, важно, чтобы приложение в этом случае не останавливало Spark Context по завершении.
* `-m` - *Опционально*. Аргумент, который указывает на то, что миграция базы данных должна быть выполнена перед
  сохранением результатов (позволяет убедиться в том, что хранилище данных в актуальном состоянии или выполнить скрипты
  для приведения его к актуальному состоянию).
* `-e` - *Опционально*. Флаг, с которым можно передать набор дополнительных переменных при старте приложения. 
  Дополнительные переменные будут добавлены в конфигурационные файлы и будут доступны для использования. Переменные 
  передаются в формате ключ-значение: `"k1=v1,k2=v2,k3=v3,...""`.
* `-v` - *Опционально*. Аргумент, с помощью которого можно назначить уровень логирования в приложении.
  По умолчанию - `INFO`.

Ниже представлен пример запуска приложения Checkita в YARN в `cluster` режиме.
Параметры подключения к хранилищу результатов указаны в файле `application.conf`, при этом реквизиты для входа могут
быть переданы как посредством переменных окружения, так и в виде дополнительных переменных при старте. 
Для более подробной информации, см. главу
[Использование Переменных Окружения и Дополнительных Переменных](../02-general-concepts/02-EnvironmentAndExtraVariables.md).

```bash
export DQ_APPLICATION="<локальный или удаленный (HDFS, S3) путь до jar с приложением>"
export DQ_DEPENDENCIES="<локальный или удаленный (HDFS, S3) путь до uber-jar с зависимостями приложения>"
export DQ_APP_CONFIG="<локальный или удаленный (HDFS, S3) путь до файла с настройками приложения>"
export DQ_JOB_CONFIGS="<локальные или удаленные (HDFS, S3) пути до файлов с конфигурацией пайплайна (разделены запятыми)>"

# Поскольку указанные файлы сначала будут загружены на драйвер и экзекьюторы,
# то они будут находиться в рабочей директории. 
# Таким образом, в аргументах приложения нужно указать только лишь имена файлов:
export DQ_APP_CONFIG_FILE=$(basename $DQ_APP_CONFIG)
export DQ_JOB_CONFIG_FILES="<job configuration files separated by commas (only file names)>"
export REFERENCE_DATE="2023-08-01"

# Входная точка для приложения (executable class): ru.raiffeisen.checkita.apps.batch.DataQualityBatchApp
# Параметр --name в spark-submit команде имеет более высокий приоритет, чем
# имя приложения указанное в настройках `application.conf`.

spark-submit\
   --class ru.raiffeisen.checkita.apps.batch.DataQualityBatchApp \
   --name "Checkita Data Quality" \
   --master yarn \
   --deploy-mode cluster \
   --num-executors 1 \
   --executor-memory 2g \
   --executor-cores 4 \
   --driver-memory 2g \
   --jars $DQ_DEPENDENCIES \
   --files "$DQ_APP_CONFIG,$DQ_DQ_JOB_CONFIGS" \
   --conf "spark.executor.memoryOverhead=2g" \
   --conf "spark.driver.memoryOverhead=2g" \
   --conf "spark.driver.maxResultSize=4g" \
   $DQ_APPLICATION \
   -a $DQ_APP_CONFIG_FILE \
   -j $DQ_JOB_CONFIG_FILES \
   -d $REFERENCE_DATE \
   -e "storage_db_user=some_db_user,storage_db_password=some_db_password"
```