# Общая Информация

Checkita работает как Spark-приложение. Соответственно, приложение может быть запущено таким же образом,
как и любое другое Spark-приложение:

* локально, на клиентской машине;
* в выделенном Spark-кластере;
* через менеджер ресурсов (Yarn, Mesos);
* в кластере Kubernetes.

Также поддерживаются оба режима запуска приложения: `client` and `cluster`.

Фреймворк разрабатывается в первую очередь для пакетной обработки данных и на данный момент поддерживает только
такой режим работы. Типовая архитектура для работы с фреймворком показана на схеме ниже:

* Собирается Uber-jar фреймворка (обычно без зависимостей самого Spark, т.к. они уже доступны на кластере).
* Подготавливается Hocon файл с общими настройками фреймворка.
* Формируется конфигурационный файл с описанием Data Quality пайплайна в соответствии с документацией.
* Запускается Spark Application.
* Spark Application загружает источники описанные в конфигурационном файле (HDFS, S3, Hive, внешние БД),
  рассчитывает метрики, выполняет проверки и сохраняет результаты:
  * Основные результаты сохраняются в базу данных фреймворка.
  * Дополнительно, результаты и уведомления отправляются по каналам настроенным в пайплайне.
* На основе результатов расчета Data Quality формируются деш-борды для мониторинга качества данных
  (не входит в функционал данного фремворка).

Также, Data Quality Framework может использоваться и для потоковой обработки данных,
однако данный функционал находится на стадии разработки.

![image](../../diagrams/Architecture.png)