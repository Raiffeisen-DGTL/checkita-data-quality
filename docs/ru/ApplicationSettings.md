# Application Settings

Настройки фреймворка хранятся в двух файлах:

* `application.conf` - файл с основными настройками приложения.
* `log4j.properties` - файл с параметрами логирования. _**Изменять данный файл не рекомендуется!**_

В файле `application.conf` указываются следующие параметры приложения:

* `application_name`: имя Spark Application по умолчанию (если не указано, то используется **Checkita Data Quality**);
* `run_configuration_version`: версия конфигурационного файла (на текущий момент поддерживаются версии 0.9 и 1.0,
  предпочтительно использовать более новую, которая описана в документации);
* `referenceDateFormat` формат даты, за которую выполняется расчет. Фактическая дата передается во флаге `-d`
  при старте и должна иметь соответсвующий формат;
* `executionDateFormat` формат даты для строкового представления фактической даты запуска приложения;
  Модель данных содержит как референсную дату (за которую выполняется расчет), так и дату запуска приложения;
* `timeZone` временная зона, в которой запускается приложение и в которой даны строковые представления даты и времени.
* `aggregatedKafkaOutput` Булевый параметр, который позволяет аггрегировать сообщения, которые отправляются в Kafka
  топик: по одному большому сообщению на каждый тип таргета (по умолчанию - false);
* `enableSharedSparkContext` Булевый параметр, который позволяет запускать приложение в кластере, где используется
  Shared SparkContext (по умолчанию - false)
* `s3_bucket`: url для подключения к бакету в s3 хранилище (по умолчанию не указывается);
* `sql_warehouse_path`: абсолютный путь до hive warehouse (по умолчанию не указывается);
* `hbase_host`: хост для подключения к HBase (по умолчанию не указывается);
* `tmp_files_management`: путь для сохранения временных файлов при работе приложения:
    * `local_fs_path`: путь в локально файловой системе;
    * `hdfsPpath`: путь в HDFS;
* `metric_error_management`: группа параметров для настройки логирования ошибок в расчете метрик:
    * `dump_directory_path`: абсолютный путь, куда будут сохраняться логи об ошибках в расчетах метрик;
    * `dump_size`: максимальное количество ошибок, которое будет логироваться для каждой метрики и каждой партиции
      (по умолчанию: 1000).
    * `empty_file`: записывать пустой файл, даже если ошибок не было (по умолчанию: false);
    * `file_config`: настройки формата, в котором записываются сообщения об ошибках:
        * `format`: формат файла (по умолчанию **csv**);
        * `delimiter`: разделитель (по умолчанию ` , `);
        * `quote`: обрамляющие кавычки (по умолчанию ` " `);
        * `escape`: символ экранирования (по умолчанию ` \ `);
        * `quote_mode`: режим обрамления значений в кавычки (по умолчанию **"ALL"**);
* `virtual_sources_management`: группа параметров для настройки сохранения виртуальных иточников:
    * `dump_directory_path`: абсолютный путь, куда будут сохраняться виртуальные источники;
    * `file_format`: формат файла, в котором будут сохраняться источники;
    * `delimiter`: разделитель (по умолчанию ` , `);
* `storage`: группа параметров для настройки подключения к БД Data Quality.
  **Указание этих параметров критично для успешной работы приложения Data Quality!**
    * `type`: способ указания параметров для подключения к БД. На текущий момент параметры подключения могут быть указаны
      либо непосредственно в файле application.conf (`type: "APP_CONFIG"`), либо в параметрах к Spark Application
      (`type: "SPARK_CONFIG"`).
    * `config`: параметры подключения к БД Data Quality (указываются только для `type: "APP_CONFIG"`);
        * `subtype`: поддерживаются следующие типы БД: **"POSTGRES"**, **"ORACLE"**, **"SQLITE"**;
        * `host`: URL для подключения;
        * `user`: логин;
        * `password`: пароль;
        * `schema`: схема в которой хранятся результаты расчетов фреймворка;
    * Если `type: "APP_CONFIG"`, то аналогичные параметры должны быть указаны в параметрах Spark Application:
        * `spark.jdbc.db_type`
        * `spark.jdbc.host`
        * `spark.jdbc.login`
        * `spark.jdbc.password`
        * `spark.jdbc.db_schema`
* `mailing`: группа параметров для настройки отправки уведомлений.
    * `notifications`: true/false - нужно ли отправлять уведомления (по умолчанию false);
    * `mode`: режим отправки уведомлений (по умолчанию не указывается - уведомления отключены).
        * `external`: используется внешний SMTP Server;
        * `internal`: используется внутренний SMTP для отправки сообщений через bash;
    * `mailing_script_path`: путь к bash-скрипту для отправки сообщений;
    * `config`:
        * `address`: e-mail отправителя;
        * `name`: имя отправителя (по умолчанию: `CIBAA DataQuality`)
        * `summarySubjectTemplate`: шаблон темы письма для отчетов о завершении расчета.
          Шаблон по умолчанию: `Data Quality summary for JobID: {{ jobId }}`
        * `checkAlertSubjectTemplate`: шаблон темы письма для уведомлений о неуспешных проверках.
          Шаблон по умолчанию: `Data Quality failed check alert for JobID: {{ jobId }}`
        * `hostname`: хост SMTP сервера;
        * `smtpPort`: порт SMTP сервера;
        * `username`: логин;
        * `password`: пароль;
        * `sslOnConnect`: true/false чтобы включить/выключить SSL secure connection.
* `mattermost`: группа параметров для настройки отправки уведомлений в Mattermost:
    * `host` - хост сервера Mattermost;
    * `token` - access token для подключения к API Mattermost.

Пример файла с настройками приложения можно найти тут: [application.conf](../examples/application.conf)