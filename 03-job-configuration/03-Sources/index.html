
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://raiffeisen-dgtl.github.io/checkita-data-quality/03-job-configuration/03-Sources/" rel="canonical"/>
<link href="../02-Schemas/" rel="prev"/>
<link href="../04-Streams/" rel="next"/>
<link href="../../logo/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.5.49" name="generator"/>
<title>Sources Configuration - Checkita Data Quality</title>
<link href="../../assets/stylesheets/main.6f8fc17f.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="yellow" data-md-color-scheme="slate" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#sources-configuration">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Checkita Data Quality" class="md-header__button md-logo" data-md-component="logo" href="../.." title="Checkita Data Quality">
<img alt="logo" src="../../logo/logo.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Checkita Data Quality
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Sources Configuration
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/Raiffeisen-DGTL/checkita-data-quality" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
</div>
<div class="md-source__repository">
    checkita-data-quality
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
        
  
    
  
  Home

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../01-application-setup/">
          
  
    
  
  Application Setup

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../02-general-information/">
          
  
    
  
  General Information

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../">
          
  
    
  
  Job Configuration

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../changelog/CHANGELOG/">
        
  
    
  
  Changelog

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../contribution/">
          
  
    
  
  Contribution

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../api/">
        
  
    
  
  Scala API Doc

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../swagger/">
        
  
    
  
  Swagger Doc

      </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Checkita Data Quality" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="Checkita Data Quality">
<img alt="logo" src="../../logo/logo.png"/>
</a>
    Checkita Data Quality
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/Raiffeisen-DGTL/checkita-data-quality" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
</div>
<div class="md-source__repository">
    checkita-data-quality
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Home
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../01-application-setup/">
<span class="md-ellipsis">
    Application Setup
  </span>
</a>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            Application Setup
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../01-application-setup/01-ApplicationSettings/">
<span class="md-ellipsis">
    Application Settings
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../01-application-setup/02-ApplicationSubmit/">
<span class="md-ellipsis">
    Submitting Data Quality Application
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../01-application-setup/03-ResultsStorage/">
<span class="md-ellipsis">
    Data Quality Results Storage
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../01-application-setup/04-APIServer/">
<span class="md-ellipsis">
    API Server
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../02-general-information/">
<span class="md-ellipsis">
    General Information
  </span>
</a>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            General Information
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/01-WorkingWithDateTime/">
<span class="md-ellipsis">
    Working with Date and Time
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/02-EnvironmentAndExtraVariables/">
<span class="md-ellipsis">
    Usage of Environment Variables and Extra Variables
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/03-StatusModel/">
<span class="md-ellipsis">
    Status Model used in Results
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/04-ErrorCollection/">
<span class="md-ellipsis">
    Metric Error Collection
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/05-StreamingMode/">
<span class="md-ellipsis">
    Data Quality Checks over Streaming Sources
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/06-MetricSQLEquivalency/">
<span class="md-ellipsis">
    Metrics SQL Equivalency
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/07-MetricCalculatorEngines/">
<span class="md-ellipsis">
    Metric Calculator Engines Overview and Benchmarking
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../02-general-information/08-CheckFailureTolerance/">
<span class="md-ellipsis">
    Check Failure Tolerance
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    Job Configuration
  </span>
</a>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            Job Configuration
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../01-Connections/">
<span class="md-ellipsis">
    Connections Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../02-Schemas/">
<span class="md-ellipsis">
    Schemas Configuration
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Sources Configuration
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Sources Configuration
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#file-sources-configuration">
<span class="md-ellipsis">
      File Sources Configuration
    </span>
</a>
<nav aria-label="File Sources Configuration" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#fixed-width-file-sources">
<span class="md-ellipsis">
      Fixed Width File Sources
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#delimited-file-sources">
<span class="md-ellipsis">
      Delimited File Sources
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#avro-file-sources">
<span class="md-ellipsis">
      Avro File Sources
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#orc-file-sources">
<span class="md-ellipsis">
      ORC File Sources
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#parquet-file-sources">
<span class="md-ellipsis">
      Parquet File Sources
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#hive-sources-configuration">
<span class="md-ellipsis">
      Hive Sources Configuration
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#table-sources-configuration">
<span class="md-ellipsis">
      Table Sources Configuration
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kafka-sources-configuration">
<span class="md-ellipsis">
      Kafka Sources Configuration
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#greenplum-sources-configuration">
<span class="md-ellipsis">
      Greenplum Sources Configuration
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#custom-sources-configuration">
<span class="md-ellipsis">
      Custom Sources Configuration
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sources-configuration-example">
<span class="md-ellipsis">
      Sources Configuration Example
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../04-Streams/">
<span class="md-ellipsis">
    Streaming Sources Configurations
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../05-VirtualSources/">
<span class="md-ellipsis">
    Virtual Sources Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../06-VirtualStreams/">
<span class="md-ellipsis">
    Virtual Streaming Sources Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../07-LoadChecks/">
<span class="md-ellipsis">
    Load Checks Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../08-Metrics/">
<span class="md-ellipsis">
    Metrics Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../09-Checks/">
<span class="md-ellipsis">
    Checks Configurations
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../10-Targets/">
<span class="md-ellipsis">
    Targets Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../11-FileOutputs/">
<span class="md-ellipsis">
    File Output Configuration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../12-JobConfigExample/">
<span class="md-ellipsis">
    Job Configuration Example
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../changelog/CHANGELOG/">
<span class="md-ellipsis">
    Changelog
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../contribution/">
<span class="md-ellipsis">
    Contribution
  </span>
</a>
<label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
            Contribution
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../contribution/code-of-conduct/">
<span class="md-ellipsis">
    Code of Conduct
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../contribution/contribution/">
<span class="md-ellipsis">
    Contribution Guide
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api/">
<span class="md-ellipsis">
    Scala API Doc
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../swagger/">
<span class="md-ellipsis">
    Swagger Doc
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="sources-configuration">Sources Configuration</h1>
<p>Reading sources is one of the major part of Data Quality job. During job execution, Checkita will read all sources into 
a Spark DataFrames, that will be later processed to calculate metrics and perform quality checks. In addition, 
dataframes' metadata is used to perform all types of load checks in order to ensure that source has the structure 
as expected.</p>
<p>Generally, sources can be read from file systems or object storage that Spark is connected to such as HDFS or S3.
In additional, table-like source from Hive catalogue can be read. Apart from integrations natively supported by Spark,
Checkita can read sources from external systems such as RDBMS or Kafka. For this purpose it is required to define
connections to these systems in a first place. See <a href="../01-Connections/">Connections Configuration</a> chapter for more 
details on connections configurations.</p>
<p>Additionally, it is possible to cache sources that in memory or on disk in order to tune application performance. 
This could be handful when source is used as a parent for more than one virtual source.
In such cases caching source allows not to calculate it multiple times.</p>
<p>Thus, currently Checkita supports four general types of sources:</p>
<ul>
<li>File sources: read files from local or remote file systems (HDFS, S3, etc.);</li>
<li>Hive sources: read hive table from Hive catalogue;</li>
<li>Table sources: read tables from RDBMS via JDBC connection.</li>
<li>Kafka sources: read topics from Kafka.</li>
<li>Greenplum sources: read tables from Greenplum via Pivotal Greenplum connector.</li>
<li>Custom sources: read from sources that are not supported directly in job configuration by providing 
  all required Spark options to connect and read from unsupported source.</li>
</ul>
<p>All sources must be defined in <code>sources</code> section of job configuration. 
More details on how to configure sources of each of these types are shown below. Example of <code>sources</code> section of 
job configuration is shown in <a href="#sources-configuration-example">Sources Configuration Example</a> below.</p>
<h2 id="file-sources-configuration">File Sources Configuration</h2>
<p>Currently, there are five file types that Checkita can read as a source. These are:</p>
<ul>
<li>Fixed-width text files;</li>
<li>Delimited text files (CSV, TSV);</li>
<li>ORC files;</li>
<li>Parquet files;</li>
<li>Avro files.</li>
</ul>
<p>When configuring file source, it is mandatory to indicate its type. Subsequently, configuration parameters may 
vary for files of different types.</p>
<p>Common parameters for sources of any file type are:</p>
<ul>
<li><code>id</code> - <em>Required</em>. Source ID;</li>
<li><code>description</code> - <em>Optional</em>. Source description;</li>
<li><code>kind</code> - <em>Required</em>. File type. Can be one of the following: <code>fixed</code>, <code>delimited</code>, <code>orc</code>, <code>parquet</code>, <code>avro</code>;</li>
<li><code>path</code> - <em>Required</em>. File path. Can be a path to a directory or a S3-bucket. In this case all files from this
  directory/bucket will be read (assuming they all have the same schema). Note, that when reading from file system which
  is not spark default file system, it is required to add FS prefix to the path, e.g. <code>file://</code> to read from local FS, 
  or <code>s3a://</code> to read from S3.</li>
<li><code>persist</code> - <em>Optional</em>. One of the allowed Spark StorageLevels used to cache sources.
  By default, sources are not cached. Supported Spark StorageLevels are:<ul>
<li><code>NONE</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_ONLY_SER</code>,
  <code>MEMORY_ONLY_SER_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>MEMORY_AND_DISK_SER</code>,
  <code>MEMORY_AND_DISK_SER_2</code>, <code>OFF_HEAP</code>.</li>
</ul>
</li>
<li><code>options</code> - <em>Optional</em>. Additional Spark parameters used to read data from the given source.</li>
<li><code>keyFields</code> - <em>Optional</em>. List of columns that form a Primary Key or are used to identify row within a dataset.
  Key fields are primarily used in error collection reports. For more details on error collection, see 
  <a href="../../02-general-information/04-ErrorCollection/">Metric Error Collection</a> chapter.</li>
<li><code>metadata</code> - <em>Optional</em>. List of user-defined metadata parameters specific to this source where each parameter
  is a string in format: <code>param.name=param.value</code>.</li>
</ul>
<h3 id="fixed-width-file-sources">Fixed Width File Sources</h3>
<p>In order to read fixed-width file it is additionally required to provide ID of the schema used to parse file content.
Schema itself should be defined in <code>schemas</code> section of job configuration as described in 
<a href="../02-Schemas/">Schemas Configuration</a> chapter. </p>
<ul>
<li><code>schema</code> - <em>Required</em>. Schema ID used to parse fixed-width file. 
  The schema definition type should be either <code>fixedFull</code> or <code>fixedShort</code></li>
</ul>
<h3 id="delimited-file-sources">Delimited File Sources</h3>
<p>When reading delimited text file, its schema may be inferred from file header if it is presented in the file or 
may be explicitly defined in <code>schemas</code> section of job configuration file as described in
<a href="../02-Schemas/">Schemas Configuration</a> chapter.</p>
<p>Thus, additional parameters for configuring delimited file source are:</p>
<ul>
<li><code>schema</code> - <em>Optional</em>. Schema ID used to parse delimited file text file. It is possible to use schema of any
  definition type as long as it has flat structure (nested columns are not supported for delimited text files).</li>
<li><code>header</code> - <em>Optional, default is <code>false</code></em>. Boolean parameter indicating whether schema should be inferred 
  from file header.</li>
<li><code>delimiter</code> - <em>Optional, default is <code>,</code></em>. Column delimiter.</li>
<li><code>quote</code> - <em>Optional, default is <code>"</code></em>. Column enclosing character.</li>
<li><code>escape</code> - <em>Optional, default is <code>\</code></em>. Escape character.</li>
</ul>
<blockquote>
<p><strong>IMPORTANT</strong>: If the <code>header</code> parameter is absent or set to<code>false</code>, then <code>schema</code> parameter must be set.
And vice versa, if <code>header</code> parameter is set to <code>true</code>, then <code>schema</code> parameter must not be set.
In other words, schema may be inferred from file header or be explicitly defined, but not both.</p>
</blockquote>
<h3 id="avro-file-sources">Avro File Sources</h3>
<p>Avro files can contain schema in its header. Therefore, there are two options to read avro files: either infer schema
from file or provide it explicitly. In the second case, schema must be defined in <code>schemas</code> section of job 
configuration file  as described in <a href="../02-Schemas/">Schemas Configuration</a> chapter. Therefore, there is only one 
additional parameter for avro file source configuration:</p>
<ul>
<li><code>schema</code> - <em>Optional</em>. Schema ID used to read avro file. It is possible to use schema of any
  definition type.</li>
</ul>
<h3 id="orc-file-sources">ORC File Sources</h3>
<p>As ORC format contains schema within itself, then there are no additional parameters required to read ORC files.</p>
<h3 id="parquet-file-sources">Parquet File Sources</h3>
<p>As Parquet format contains schema within itself, then there are no additional parameters required to read Parquet files.</p>
<h2 id="hive-sources-configuration">Hive Sources Configuration</h2>
<p>In order to read data from Hive table it is required to provide following:</p>
<ul>
<li><code>id</code> - <em>Required</em>. Source ID;</li>
<li><code>description</code> - <em>Optional</em>. Source description;</li>
<li><code>schema</code> - <em>Required</em>. Hive schema.</li>
<li><code>table</code> - <em>Required</em>. Hive table.</li>
<li><code>partitions</code> - <em>Optional</em>. List of partitions to read where each element is an object with following fields.
  If partitions are not set then entire table is read.<ul>
<li><code>name</code> - <em>Required</em>. Partition column name</li>
<li><code>expr</code> - <em>Optional</em>. SQL expression used to filter partitions to read. This SQL expression must contain
only reference to partition column that is being filtered (one that is defined in <code>name</code> field). References to
other columns are not allowed as well as any SQL sub-queries. It is allowed to use all types of SQL 
functions and literals.<blockquote>
<p><strong>IMPORTANT</strong>: If parameterless function is used, it should be called with empty parentheses, e.g.: current_date()</p>
</blockquote>
</li>
<li><code>values</code> - <em>Optional</em>. List of partition column name values to read.<blockquote>
<p><strong>IMPORTANT</strong>: When defining partitions to read, it is required to specify either an SQL expression to filter
partitions or an explicit list of partition values but not both.</p>
</blockquote>
</li>
</ul>
</li>
<li><code>persist</code> - <em>Optional</em>. One of the allowed Spark StorageLevels used to cache sources.
  By default, sources are not cached. Supported Spark StorageLevels are:<ul>
<li><code>NONE</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_ONLY_SER</code>,
  <code>MEMORY_ONLY_SER_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>MEMORY_AND_DISK_SER</code>,
  <code>MEMORY_AND_DISK_SER_2</code>, <code>OFF_HEAP</code>.</li>
</ul>
</li>
<li><code>keyFields</code> - <em>Optional</em>. List of columns that form a Primary Key or are used to identify row within a dataset.
  Key fields are primarily used in error collection reports. For more details on error collection, see
  <a href="../../02-general-information/04-ErrorCollection/">Metric Error Collection</a> chapter.</li>
<li><code>metadata</code> - <em>Optional</em>. List of user-defined metadata parameters specific to this source where each parameter
  is a string in format: <code>param.name=param.value</code>.</li>
</ul>
<h2 id="table-sources-configuration">Table Sources Configuration</h2>
<p>Table source are read from supported RDBMS via JDBC connection. There are two options to read data from RDBMS:</p>
<ul>
<li>read entire table content;</li>
<li>execute query on the RDBMS side and read only query result.</li>
</ul>
<p>In order to set up table source, it is required to
supply following parameters:</p>
<ul>
<li><code>id</code> - <em>Required</em>. Source ID;</li>
<li><code>description</code> - <em>Optional</em>. Source description;</li>
<li><code>connection</code> - <em>Required</em>. Connection ID to use for table source. Connection ID must refer to connection configuration
  for one of the supported RDBMS. See <a href="../01-Connections/">Connections Configuration</a> chapter for more information.</li>
<li><code>table</code> - <em>Optional</em>. Table to read.</li>
<li><code>query</code> - <em>Optional</em>. Query to execute. Query result is read as table source.</li>
<li><code>persist</code> - <em>Optional</em>. One of the allowed Spark StorageLevels used to cache sources.
  By default, sources are not cached. Supported Spark StorageLevels are:<ul>
<li><code>NONE</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_ONLY_SER</code>,
  <code>MEMORY_ONLY_SER_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>MEMORY_AND_DISK_SER</code>,
  <code>MEMORY_AND_DISK_SER_2</code>, <code>OFF_HEAP</code>.</li>
</ul>
</li>
<li><code>keyFields</code> - <em>Optional</em>. List of columns that form a Primary Key or are used to identify row within a dataset.
  Key fields are primarily used in error collection reports. For more details on error collection, see
  <a href="../../02-general-information/04-ErrorCollection/">Metric Error Collection</a> chapter.</li>
<li><code>metadata</code> - <em>Optional</em>. List of user-defined metadata parameters specific to this source where each parameter
  is a string in format: <code>param.name=param.value</code>.</li>
</ul>
<blockquote>
<p><strong>IMPORTANT</strong>: Either <code>table</code> to read from must be specified or <code>query</code> to execute, but not both.
In addition, using queries is only allowed when <code>allowSqlQueries</code> is set to true. Otherwise, any usage of arbitrary
SQL queries will not be permitted. See <a href="../../01-application-setup/01-ApplicationSettings/#enablers">Enablers</a> chapter
for more information.</p>
<p><strong>TIP</strong>: HOCON format supports multiline string values. In order to define such a value, it is required to enclose
string in triple quotes, e.g.:
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1">multilineString: """
</span><span id="__span-0-2">  SELECT * from schema.table
</span><span id="__span-0-3">  WHERE load_date = '2023-08-23';
</span><span id="__span-0-4">"""
</span></code></pre></div></p>
</blockquote>
<h2 id="kafka-sources-configuration">Kafka Sources Configuration</h2>
<p>Despite, it is not common situation to read messages from Kafka topics in batch-mode, such feature is presented in 
Checkita framework. In order to set up source that reads from Kafka topic/s, it is required to provide following
parameters:</p>
<ul>
<li><code>id</code> - <em>Required</em>. Source ID;</li>
<li><code>description</code> - <em>Optional</em>. Source description;</li>
<li><code>connection</code> - <em>Required</em>. Connection ID to use for kafka source. Connection ID must refer to Kafka connection 
  configuration. See <a href="../01-Connections/">Connections Configuration</a> chapter for more information.</li>
<li><code>topics</code> - <em>Optional</em>. List of topics to read. Topics can be specified in either of two formats:<ul>
<li>List of topics without indication of partitions to read (read all topic partitions): <code>["topic1", "topic2"]</code>;</li>
<li>List of topics with indication of partitions to read: <code>["topic1@[0, 1]", "topic2@[2, 4]"]</code></li>
<li><em>All topics must be defined using the same format.</em></li>
</ul>
</li>
<li><code>topicPattern</code> - <em>Optional</em>. Topic pattern: read all topics that match pattern.</li>
<li><code>startingOffsets</code> - <em>Optional, default is <code>earliest</code></em>. Json string setting starting offsets to read from topic.
  By default, all topic is read.</li>
<li><code>endingOffsets</code> - <em>Optional, default is <code>latest</code></em>. Json string setting ending offset until which to read from topic.
  By default, read topic till the end.</li>
<li><code>keyFormat</code> - <em>Optional, default is <code>string</code></em>. Format used to decode message key.</li>
<li><code>valueFormat</code> - <em>Optional, default is <code>string</code></em>. Format used to decode message value.</li>
<li><code>keySchema</code> - Schema ID used to parse message key. If key format other than <code>string</code> then schema must be provided.</li>
<li><code>valueSchema</code> - Schema ID used to parse message value. If value format other than <code>string</code> then schema must be provided.</li>
<li><code>subtractSchemaId</code> - <em>Optional, default is <code>false</code></em>. Boolean flag indicating whether a kafka message schema ID is
  encoded into its value, i.e. <code>[1 Magic Byte] + [4 Schema ID Bytes] + [Message Value Binary Data]</code>.
  If set to <code>true</code>, then first five bytes are subtracted before value parsing.</li>
<li><code>options</code> - <em>Optional</em>. Additional Spark parameters related to reading messages from Kafka topics such as:
  <code>failOnDataLoss, kafkaConsumer.pollTimeoutMs, fetchOffset.numRetries, fetchOffset.retryIntervalMs, maxOffsetsPerTrigger</code>.
  Parameters are provided as a strings in format of <code>parameterName=parameterValue</code>.
  For more information, see <a href="https://spark.apache.org/docs/2.3.2/structured-streaming-kafka-integration.html">Spark Kafka Integration Guide</a>.</li>
<li><code>persist</code> - <em>Optional</em>. One of the allowed Spark StorageLevels used to cache sources.
  By default, sources are not cached. Supported Spark StorageLevels are:<ul>
<li><code>NONE</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_ONLY_SER</code>,
  <code>MEMORY_ONLY_SER_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>MEMORY_AND_DISK_SER</code>,
  <code>MEMORY_AND_DISK_SER_2</code>, <code>OFF_HEAP</code>.</li>
</ul>
</li>
<li><code>keyFields</code> - <em>Optional</em>. List of columns that form a Primary Key or are used to identify row within a dataset.
  Key fields are primarily used in error collection reports. For more details on error collection, see
  <a href="../../02-general-information/04-ErrorCollection/">Metric Error Collection</a> chapter.</li>
<li><code>metadata</code> - <em>Optional</em>. List of user-defined metadata parameters specific to this source where each parameter
  is a string in format: <code>param.name=param.value</code>.</li>
</ul>
<p>Currently, <code>binary</code>, <code>string</code>, <code>xml</code>, <code>json</code> and <code>avro</code> formats are supported to decode message key and value.
Note, that when <code>binary</code> format is selected, then kafka key or value is not decoded but rather selected as is.
Thus, it is up to user to use virtual sources capabilities to cast binary column into data types suitable for
data quality checks.</p>
<blockquote>
<p><em>TIP</em>: In order to define JSON strings, they must be enclosed in triple quotes:
<code>"""{"name1": {"name2": "value2", "name3": "value3""}}"""</code>.</p>
</blockquote>
<h2 id="greenplum-sources-configuration">Greenplum Sources Configuration</h2>
<p>In order to read data from Greenplum table using pivotal connector it is required to provide following:</p>
<ul>
<li><code>id</code> - <em>Required</em>. Source ID;</li>
<li><code>description</code> - <em>Optional</em>. Source description;</li>
<li><code>connection</code> - <em>Required</em>. Connection ID to use for table source. Connection ID must refer to Greenplum pivotal
  connection. See <a href="../01-Connections/">Connections Configuration</a> chapter for more information.</li>
<li><code>table</code> - <em>Optional</em>. Table to read.</li>
<li><code>persist</code> - <em>Optional</em>. One of the allowed Spark StorageLevels used to cache sources.
  By default, sources are not cached. Supported Spark StorageLevels are:<ul>
<li><code>NONE</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_ONLY_SER</code>,
  <code>MEMORY_ONLY_SER_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>MEMORY_AND_DISK_SER</code>,
  <code>MEMORY_AND_DISK_SER_2</code>, <code>OFF_HEAP</code>.</li>
</ul>
</li>
<li><code>keyFields</code> - <em>Optional</em>. List of columns that form a Primary Key or are used to identify row within a dataset.
  Key fields are primarily used in error collection reports. For more details on error collection, see
  <a href="../../02-general-information/04-ErrorCollection/">Metric Error Collection</a> chapter.</li>
<li><code>metadata</code> - <em>Optional</em>. List of user-defined metadata parameters specific to this source where each parameter
  is a string in format: <code>param.name=param.value</code>.</li>
</ul>
<h2 id="custom-sources-configuration">Custom Sources Configuration</h2>
<p>Custom sources can be used in cases when it is required to read data from the source type that is not explicitly
supported (by one of the configuration described above). In order to configure a custom source, it is required to
provide following parameters:</p>
<ul>
<li><code>id</code> - <em>Required</em>. Source ID;</li>
<li><code>description</code> - <em>Optional</em>. Source description;</li>
<li><code>format</code> - <em>Required</em>. Spark DataFrame reader format that is used to read from the given source.</li>
<li><code>path</code> - <em>Optional</em>. Path to read data from (if required).</li>
<li><code>schema</code> - <em>Optional</em>. Explicit schema to be applied to data from the given source (if required).</li>
<li><code>persist</code> - <em>Optional</em>. One of the allowed Spark StorageLevels used to cache sources.
  By default, sources are not cached. Supported Spark StorageLevels are:<ul>
<li><code>NONE</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_ONLY_SER</code>,
  <code>MEMORY_ONLY_SER_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>MEMORY_AND_DISK_SER</code>,
  <code>MEMORY_AND_DISK_SER_2</code>, <code>OFF_HEAP</code>.</li>
</ul>
</li>
<li><code>keyFields</code> - <em>Optional</em>. List of columns that form a Primary Key or are used to identify row within a dataset.
  Key fields are primarily used in error collection reports. For more details on error collection, see
  <a href="../../02-general-information/04-ErrorCollection/">Metric Error Collection</a> chapter.</li>
<li><code>metadata</code> - <em>Optional</em>. List of user-defined metadata parameters specific to this source where each parameter
  is a string in format: <code>param.name=param.value</code>.</li>
</ul>
<p>After parameters above are defined then spark DataFrame reader is set up to read data from the source as follows:</p>
<div class="language-scala highlight"><pre><span></span><code><span id="__span-1-1"><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="n">format</span><span class="p">).</span><span class="n">schema</span><span class="p">(</span><span class="n">schema</span><span class="p">).</span><span class="n">options</span><span class="p">(</span><span class="n">options</span><span class="p">).</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span></code></pre></div>
<p>If any of the optional parameters is missing than corresponding Spark reader configuration is not set.</p>
<h2 id="sources-configuration-example">Sources Configuration Example</h2>
<p>As it is shown in the example below, sources of the same type are grouped within subsections named after the type
of the source. These subsections should contain a list of source configurations of the corresponding type.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1">  sources: {
</span><span id="__span-2-2">    file: [
</span><span id="__span-2-3">      {id: "hdfs_fixed_file", kind: "fixed", path: "path/to/fixed/file.txt", schema: "schema2"}
</span><span id="__span-2-4">      {
</span><span id="__span-2-5">        id: "hdfs_delimited_source",
</span><span id="__span-2-6">        description: "Reading static data from CSV file"
</span><span id="__span-2-7">        kind: "delimited",
</span><span id="__span-2-8">        path: "path/to/csv/file.csv"
</span><span id="__span-2-9">        schema: "schema1"
</span><span id="__span-2-10">        medadata: [
</span><span id="__span-2-11">          "data.owner=some.person@some.domain"
</span><span id="__span-2-12">          "file.version=1.1"
</span><span id="__span-2-13">        ]
</span><span id="__span-2-14">      }
</span><span id="__span-2-15">      {id: "hdfs_avro_source", kind: "avro", path: "path/to/avro/file.avro", schema: "avro_schema"}
</span><span id="__span-2-16">      {id: "hdfs_orc_source", kind: "orc", path: "path/to/orc/file.orc"}
</span><span id="__span-2-17">    ]
</span><span id="__span-2-18">    hive: [
</span><span id="__span-2-19">      {
</span><span id="__span-2-20">        id: "hive_source_1", schema: "some_schema", table: "some_table",
</span><span id="__span-2-21">        partitions: [{name: "load_date", values: ["2023-06-30", "2023-07-01"]}],
</span><span id="__span-2-22">        keyFields: ["id", "name"]
</span><span id="__span-2-23">      }
</span><span id="__span-2-24">    ]
</span><span id="__span-2-25">    table: [
</span><span id="__span-2-26">      {id: "table_source_1", connection: "oracle_db1", table: "some_table", keyFields: ["id", "name"]}
</span><span id="__span-2-27">      {id: "table_source_2", connection: "sqlite_db", table: "other_table"}
</span><span id="__span-2-28">    ]
</span><span id="__span-2-29">    kafka: [
</span><span id="__span-2-30">      {
</span><span id="__span-2-31">        id: "kafka_source_1",
</span><span id="__span-2-32">        connection: "kafka_broker",
</span><span id="__span-2-33">        topics: ["topic1.pub", "topic2.pub"]
</span><span id="__span-2-34">        format: "json"
</span><span id="__span-2-35">      }
</span><span id="__span-2-36">      {
</span><span id="__span-2-37">        id: "kafka_source_2",
</span><span id="__span-2-38">        brokerId: "kafka_broker",
</span><span id="__span-2-39">        topics: ["topic3.pub@[1,3]"]
</span><span id="__span-2-40">        startingOffsets: """{"topic3.pub":{"1":1234,"3":2314}}"""
</span><span id="__span-2-41">        options: ["kafkaConsumer.pollTimeoutMs=300000"]
</span><span id="__span-2-42">        format: "json"
</span><span id="__span-2-43">      }
</span><span id="__span-2-44">    ]
</span><span id="__span-2-45">    greenplum: [
</span><span id="__span-2-46">      {id: "greenplum_source_1", connection: "greenplum_db", table: "some_table"}
</span><span id="__span-2-47">    ]
</span><span id="__span-2-48">  }
</span></code></pre></div>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>